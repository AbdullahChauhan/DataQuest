{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles for the App Store and Google Play Markets\n",
    "\n",
    "Our aim in this project is to find mobile app profiles that are profitable for the App Store and Google Play markets. We're working as data analysts for a company that builds Android and iOS mobile apps, and our job is to enable our team of developers to make data-driven decisions with respect to the kind of apps they build.\n",
    "\n",
    "At our company, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. This means that our revenue for any given app is mostly influenced by the number of users that use our app. Our goal for this project is to analyze data to help our developers understand what kinds of apps are likely to attract more users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring the Data\n",
    "\n",
    "Collecting data for over 4 million apps requires a significant amount of time and money, so we'll try to analyze a sample of the data instead. To avoid spending resources on collecting new data ourselves, we should first try to see if we can find any relevant existing data at no cost. Luckily, these are two data sets that seem suitable for our goals:\n",
    "\n",
    "- A [data set](https://www.kaggle.com/lava18/google-play-store-apps) containing data about approximately 10,000 Android apps from Google Play; the data was collected in August 2018. You can download the data set directly from [this link](https://dq-content.s3.amazonaws.com/350/googleplaystore.csv).\n",
    "- A [data set](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps) containing data about approximately 7,000 iOS apps from the App Store; the data was collected in July 2017. You can download the data set directly from [this link](https://dq-content.s3.amazonaws.com/350/AppleStore.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by opening and then continue with exploring these two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# for apple store\n",
    "opened_file = open('AppleStore.csv', encoding=\"utf8\")\n",
    "read_file = reader(opened_file)\n",
    "ios_data = list(read_file)\n",
    "\n",
    "# get the header separately\n",
    "ios_header = ios_data[0]\n",
    "#now exclude the header\n",
    "ios_data = ios_data[1:]\n",
    "\n",
    "# for android play store\n",
    "opened_file = open('googleplaystore.csv', encoding=\"utf8\")\n",
    "read_file = reader(opened_file)\n",
    "android_data = list(read_file)\n",
    "\n",
    "# get the header separately\n",
    "android_header = android_data[0]\n",
    "#now exclude the header\n",
    "android_data = android_data[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function `explore_data()` so that we'll read the both dataset in a easier way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns = False):\n",
    "    data_slice = dataset[start:end]\n",
    "    \n",
    "    for row in data_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows: ', len(dataset))\n",
    "        print('Number of columns: ', len(dataset[0]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows:  10841\n",
      "Number of columns:  13\n",
      "\n",
      "\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
      "\n",
      "\n",
      "['', 'id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['1', '281656475', 'PAC-MAN Premium', '100788224', 'USD', '3.99', '21292', '26', '4', '4.5', '6.3.5', '4+', 'Games', '38', '5', '10', '1']\n",
      "\n",
      "\n",
      "['2', '281796108', 'Evernote - stay organized', '158578688', 'USD', '0', '161065', '26', '4', '3.5', '8.2.2', '4+', 'Productivity', '37', '5', '23', '1']\n",
      "\n",
      "\n",
      "['3', '281940292', 'WeatherBug - Local Weather, Radar, Maps, Alerts', '100524032', 'USD', '0', '188583', '2822', '3.5', '4.5', '5.0.0', '4+', 'Weather', '37', '5', '3', '1']\n",
      "\n",
      "\n",
      "Number of rows:  7197\n",
      "Number of columns:  17\n"
     ]
    }
   ],
   "source": [
    "# checking for android\n",
    "print(android_header)\n",
    "print('\\n')\n",
    "explore_data(android_data, 0, 3, True)\n",
    "\n",
    "print('\\n')\n",
    "print ('= = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
    "print('\\n')\n",
    "\n",
    "# checking for ios\n",
    "print(ios_header)\n",
    "print('\\n')\n",
    "explore_data(ios_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Wrong Data\n",
    "The Google Play data set has a dedicated [discussion section](https://www.kaggle.com/lava18/google-play-store-apps/discussion), and we can see that one of the [discussions](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) outlines an error for row 10472. Let's print this row and compare it against the header and another row that is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "# printing the data and comparing it with another correct data row\n",
    "\n",
    "# header\n",
    "print(android_header)\n",
    "\n",
    "# wrong data row\n",
    "print(android_data[10472])\n",
    "\n",
    "# any correct data row\n",
    "print(android_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row 10472 corresponds to the app Life Made WI-Fi Touchscreen Photo Frame, The row is actually missing its \"Category\" value, which causes the column shift. As a consequence, we'll delete this row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n",
      "10840\n"
     ]
    }
   ],
   "source": [
    "# printing the length of the data list\n",
    "print(len(android_data))\n",
    "\n",
    "# don't run this more than once\n",
    "del android_data[10472]\n",
    "\n",
    "# printing the length again for checking purpose\n",
    "print(len(android_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicates Entries\n",
    "### For Android Apps\n",
    "### Part One\n",
    "\n",
    "If we explore the Google Play data set long enough, we'll find that some apps have more than one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'SOCIAL', '4.1', '78158306', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'August 3, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577446', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66577313', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Twitter', 'NEWS_AND_MAGAZINES', '4.3', '11667403', 'Varies with device', '500,000,000+', 'Free', '0', 'Mature 17+', 'News & Magazines', 'August 6, 2018', 'Varies with device', 'Varies with device']\n",
      "['Twitter', 'NEWS_AND_MAGAZINES', '4.3', '11667403', 'Varies with device', '500,000,000+', 'Free', '0', 'Mature 17+', 'News & Magazines', 'August 6, 2018', 'Varies with device', 'Varies with device']\n",
      "['Instagram', 'SOCIAL', '4.5', '66509917', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'July 31, 2018', 'Varies with device', 'Varies with device']\n",
      "['Facebook', 'SOCIAL', '4.1', '78128208', 'Varies with device', '1,000,000,000+', 'Free', '0', 'Teen', 'Social', 'August 3, 2018', 'Varies with device', 'Varies with device']\n",
      "['Twitter', 'NEWS_AND_MAGAZINES', '4.3', '11657972', 'Varies with device', '500,000,000+', 'Free', '0', 'Mature 17+', 'News & Magazines', 'July 30, 2018', 'Varies with device', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "# let's check for some famous apps\n",
    "for app in android_data:\n",
    "    app_name = app[0]\n",
    "    if app_name == 'Facebook':\n",
    "        print(app)\n",
    "    elif app_name == 'Twitter':\n",
    "        print(app)\n",
    "    elif app_name == 'Instagram':\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we explored, that we've too many duplicated entries in our android_data. And may be if we explore ios_data, we should find out some duplications there too. So better if we first separate the unique apps and duplicate apps, this way we get the count of how many duplicated apps we've. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique apps: 9659\n",
      "\n",
      "\n",
      "Number of duplicate apps: 1181\n",
      "\n",
      "\n",
      "Examples of duplicate apps: ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses', 'HipChat - Chat Built for Teams', 'Xero Accounting Software', 'MailChimp - Email, Marketing Automation', 'Crew - Free Messaging and Scheduling', 'Asana: organize team projects', 'Google Analytics', 'AdWords Express', 'Accounting App - Zoho Books', 'Invoice & Time Tracking - Zoho', 'join.me - Simple Meetings', 'Invoice 2go — Professional Invoices and Estimates', 'SignEasy | Sign and Fill PDF and other Documents']\n"
     ]
    }
   ],
   "source": [
    "# creating empty lists\n",
    "android_unique_apps = []\n",
    "android_duplicate_apps = []\n",
    "\n",
    "# looping through android apps data\n",
    "for app in android_data:\n",
    "    # getting the app name from the first column\n",
    "    app_name = app[0]\n",
    "    \n",
    "    # check if app is duplicate (appearing twice or more) - \n",
    "    # if its in unique app list, its mean the app is duplicated\n",
    "    if app_name in android_unique_apps:\n",
    "        # added into duplicate list\n",
    "        android_duplicate_apps.append(app_name)\n",
    "    else:\n",
    "        # if not added to unique list\n",
    "        android_unique_apps.append(app_name)\n",
    "        \n",
    "# printing the results\n",
    "print('Number of Unique apps:', len(android_unique_apps))\n",
    "print('\\n')\n",
    "print('Number of duplicate apps:', len(android_duplicate_apps))\n",
    "print('\\n')\n",
    "print('Examples of duplicate apps:', android_duplicate_apps[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to count certain apps more than once when we analyze data, so we need to remove the duplicate entries and keep only one entry per app. One thing we could do is remove the duplicate rows randomly, but we could probably find a better way.\n",
    "\n",
    "If you examine the rows we printed two cells above for the Instagram app, the main difference happens on the fourth position of each row, which corresponds to the number of reviews. The different numbers show that the data was collected at different times. We can use this to build a criterion for keeping rows. We won't remove rows randomly, but rather we'll keep the rows that have the highest number of reviews because the higher the number of reviews, the more reliable the ratings.\n",
    "\n",
    "To do that, we will:\n",
    "\n",
    "- Create a dictionary where each key is a unique app name, and the value is the highest number of reviews of that app\n",
    "- Use the dictionary to create a new data set, which will have only one entry per app (and we only select the apps with the highest number of reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two\n",
    "\n",
    "Building the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which index is of reviews\n",
    "# print(android_data[77][3])\n",
    "\n",
    "# initializing empty dictionary for story reviews for each app (only max one)\n",
    "reviews_max = {}\n",
    "\n",
    "# looping through android apps data\n",
    "for app in android_data:\n",
    "    # getting the app name from the first column\n",
    "    app_name = app[0]\n",
    "    \n",
    "    # getting the app review from the fourth column\n",
    "    app_review = float(app[3])\n",
    "    \n",
    "    # checking if app is already in dict and if it is, only store the maximum review entry into the dict against the app name\n",
    "    if app_name in reviews_max and reviews_max[app_name] < app_review:\n",
    "        reviews_max[app_name] = app_review\n",
    "    \n",
    "    # if not, simply put the review in dict against the app name\n",
    "    elif app_review not in reviews_max:\n",
    "        reviews_max[app_name] = app_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous code cell, we found that there are 1,181 cases where an app occurs more than once, so the length of our dictionary (of unique apps) should be equal to the difference between the length of our data set and 1,181."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length of data list: 9659\n",
      "Actual length of dictionary: 9659\n"
     ]
    }
   ],
   "source": [
    "print('Expected length of data list:', len(android_data) - len(android_duplicate_apps))\n",
    "print('Actual length of dictionary:', len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the reviews_max dictionary to remove the duplicates. For the duplicate cases, we'll only keep the entries with the highest number of reviews. In the code cell below:\n",
    "\n",
    "- We start by initializing two empty lists, android_clean and already_added.\n",
    "- We loop through the android data set, and for every iteration:\n",
    "  - We isolate the name of the app and the number of reviews.\n",
    "  - We add the current row (app) to the android_clean list, and the app name (name) to the already_added list if:\n",
    "      - The number of reviews of the current app matches the number of reviews of that app as described in the reviews_max dictionary; and\n",
    "      - The name of the app is not already in the already_added list. We need to add this supplementary condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry (for example, the Box app has three entries, and the number of reviews is the same). If we just check for reviews_max[name] == n_reviews, we'll still end up with duplicate entries for some apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two lists - \n",
    "# first for separating the clearning data\n",
    "# second to make sure the data is not repeated again\n",
    "android_clean_data = []\n",
    "already_added_data_android = []\n",
    "\n",
    "# # looping through android apps data\n",
    "for app in android_data:\n",
    "    # getting the app name from the first column\n",
    "    app_name = app[0]\n",
    "    \n",
    "    # getting the app review from the fourth column\n",
    "    app_review = float(app[3])\n",
    "    \n",
    "    # checking if current review exists in our reviews_max dict -\n",
    "    # and at the same time, checking data is not get repeated\n",
    "    if(reviews_max[app_name] == app_review) and (app_name not in already_added_data_android):\n",
    "        android_clean_data.append(app)\n",
    "        already_added_data_android.append(app_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's quickly explore the new data set, and confirm that the number of rows is 9,659."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "['Pixel Draw - Number Art Coloring Book', 'ART_AND_DESIGN', '4.3', '967', '2.8M', '100,000+', 'Free', '0', 'Everyone', 'Art & Design;Creativity', 'June 20, 2018', '1.1', '4.4 and up']\n",
      "\n",
      "\n",
      "['Paper flowers instructions', 'ART_AND_DESIGN', '4.4', '167', '5.6M', '50,000+', 'Free', '0', 'Everyone', 'Art & Design', 'March 26, 2017', '1.0', '2.3 and up']\n",
      "\n",
      "\n",
      "Number of rows:  9659\n",
      "Number of columns:  13\n"
     ]
    }
   ],
   "source": [
    "explore_data(android_clean_data, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9659 rows, just as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicates Entries\n",
    "### For iOS Apps\n",
    "### Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Actual apps:  7197\n",
      "Number of Unique apps:  7195\n",
      "Number of Duplicate apps:  2\n",
      "Duplicate apps names:  ['7579', '1089824278', 'VR Roller Coaster', '240964608', 'USD', '0', '67', '44', '3.5', '4', '0.81', '4+', 'Games', '38', '0', '1', '1'] ['10885', '1178454060', 'Mannequin Challenge', '59572224', 'USD', '0', '105', '58', '4', '4.5', '1.0.1', '4+', 'Games', '38', '5', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "# checking ios data for duplications\n",
    "ios_unique_apps = []\n",
    "ios_duplicate_apps = []\n",
    "\n",
    "for app in ios_data:\n",
    "    app_name = app[2]\n",
    "    \n",
    "    if app_name not in ios_unique_apps:\n",
    "        ios_unique_apps.append(app_name)\n",
    "    else:\n",
    "        ios_duplicate_apps.append(app)\n",
    "        \n",
    "print('Number of Actual apps: ', len(ios_data))\n",
    "print('Number of Unique apps: ', len(ios_unique_apps))\n",
    "print('Number of Duplicate apps: ', len(ios_duplicate_apps))\n",
    "print('Duplicate apps names: ', ios_duplicate_apps[0], ios_duplicate_apps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we end up finding only two apps are repeating. Other than the data is completely fine and not required cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two\n",
    "Building the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing empty dictionary for story reviews for each app (only max one)\n",
    "rating_count_max = {}\n",
    "\n",
    "# looping through android apps data\n",
    "for app in ios_data:\n",
    "    # getting the app name from the first column\n",
    "    app_name = app[2]\n",
    "    \n",
    "    # getting the app review from the fourth column\n",
    "    app_rating_count = float(app[6])\n",
    "    \n",
    "    # checking if app is already in dict and if it is, only store the maximum review entry into the dict against the app name\n",
    "    if app_name in rating_count_max and rating_count_max[app_name] < app_rating_count:\n",
    "        rating_count_max[app_name] = app_rating_count\n",
    "    \n",
    "    # if not, simply put the review in dict against the app name\n",
    "    elif app_rating_count not in rating_count_max:\n",
    "        rating_count_max[app_name] = app_rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length of data list: 7195\n",
      "Actual length of dictionary: 7195\n"
     ]
    }
   ],
   "source": [
    "print('Expected length of data list:', len(ios_data) - len(ios_duplicate_apps))\n",
    "print('Actual length of dictionary:', len(rating_count_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two lists - \n",
    "# first for separating the clearning data\n",
    "# second to make sure the data is not repeated again\n",
    "ios_clean_data = []\n",
    "already_added_data_ios = []\n",
    "\n",
    "# # looping through android apps data\n",
    "for app in ios_data:\n",
    "    # getting the app name from the first column\n",
    "    app_name = app[2]\n",
    "    \n",
    "    # getting the app review from the fourth column\n",
    "    rating_count = float(app[6])\n",
    "    \n",
    "    # checking if current review exists in our reviews_max dict -\n",
    "    # and at the same time, checking data is not get repeated\n",
    "    if(rating_count_max[app_name] == rating_count) and (app_name not in already_added_data_ios):\n",
    "        ios_clean_data.append(app)\n",
    "        already_added_data_ios.append(app_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '281656475', 'PAC-MAN Premium', '100788224', 'USD', '3.99', '21292', '26', '4', '4.5', '6.3.5', '4+', 'Games', '38', '5', '10', '1']\n",
      "\n",
      "\n",
      "['2', '281796108', 'Evernote - stay organized', '158578688', 'USD', '0', '161065', '26', '4', '3.5', '8.2.2', '4+', 'Productivity', '37', '5', '23', '1']\n",
      "\n",
      "\n",
      "['3', '281940292', 'WeatherBug - Local Weather, Radar, Maps, Alerts', '100524032', 'USD', '0', '188583', '2822', '3.5', '4.5', '5.0.0', '4+', 'Weather', '37', '5', '3', '1']\n",
      "\n",
      "\n",
      "['4', '282614216', 'eBay: Best App to Buy, Sell, Save! Online Shopping', '128512000', 'USD', '0', '262241', '649', '4', '4.5', '5.10.0', '12+', 'Shopping', '37', '5', '9', '1']\n",
      "\n",
      "\n",
      "['5', '282935706', 'Bible', '92774400', 'USD', '0', '985920', '5320', '4.5', '5', '7.5.1', '4+', 'Reference', '37', '5', '45', '1']\n",
      "\n",
      "\n",
      "Number of rows:  7195\n",
      "Number of columns:  17\n"
     ]
    }
   ],
   "source": [
    "explore_data(ios_clean_data, 0, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
